{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxing Exercise: Compute the ACF\n",
    "In the last chapter, you computed autocorrelations with one lag. Often we are interested in seeing the autocorrelation over many lags. The quarterly earnings for H&R Block (ticker symbol HRB) is plotted on the right, and you can see the extreme cyclicality of its earnings. A vast majority of its earnings occurs in the quarter that taxes are due.\n",
    "\n",
    "You will compute the array of autocorrelations for the H&R Block quarterly earnings that is pre-loaded in the DataFrame HRB. Then, plot the autocorrelation function using the plot_acf module. This plot shows what the autocorrelation function looks like for cyclical earnings data. The ACF at lag=0 is always one, of course. In the next exercise, you will learn about the confidence interval for the ACF, but for now, suppress the confidence interval by setting alpha=1.\n",
    "\n",
    "1. Import the acf module and plot_acf module from statsmodels.\n",
    "2. Compute the array of autocorrelations of the quarterly earnings data in DataFrame HRB.\n",
    "3. Plot the autocorrelation function of the quarterly earnings data in HRB, and pass the argument alpha=1 to suppress the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the acf module and the plot_acf module from statsmodels\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Compute the acf array of HRB\n",
    "acf_array = acf(HRB)\n",
    "print(acf_array)\n",
    "\n",
    "# Plot the acf function\n",
    "plot_acf(HRB, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are We Confident This Stock is Mean Reverting?\n",
    "In the last chapter, you saw that the autocorrelation of MSFT's weekly stock returns was -0.16. That autocorrelation seems large, but is it statistically significant? In other words, can you say that there is less than a 5% chance that we would observe such a large negative autocorrelation if the true autocorrelation were really zero? And are there any autocorrelations at other lags that are significantly different from zero?\n",
    "\n",
    "Even if the true autocorrelations were zero at all lags, in a finite sample of returns you won't see the estimate of the autocorrelations exactly zero. In fact, the standard deviation of the sample autocorrelation is 1/N−−√ where N is the number of observations, so if N=100, for example, the standard deviation of the ACF is 0.1, and since 95% of a normal curve is between +1.96 and -1.96 standard deviations from the mean, the 95% confidence interval is ±1.96/N−−√. This approximation only holds when the true autocorrelations are all zero.\n",
    "\n",
    "You will compute the actual and approximate confidence interval for the ACF, and compare it to the lag-one autocorrelation of -0.16 from the last chapter. The weekly returns of Microsoft is pre-loaded in a DataFrame called returns.\n",
    "\n",
    "1. Recompute the autocorrelation of weekly returns in the Series 'Adj Close' in the returns DataFrame.\n",
    "2. Find the number of observations in the returns DataFrame using the len() function.\n",
    "3. Approximate the 95% confidence interval of the estimated autocorrelation. The math function sqrt() has been imported and can be used.\n",
    "4. Plot the autocorrelation function of returns using plot_acf that was imported from statsmodels. Set alpha=0.05 for the confidence intervals (that's the default) and lags=20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the plot_acf module from statsmodels and sqrt from math\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from math import sqrt\n",
    "\n",
    "# Compute and print the autocorrelation of MSFT weekly returns\n",
    "autocorrelation = returns['Adj Close'].autocorr()\n",
    "print(\"The autocorrelation of weekly MSFT returns is %4.2f\" %(autocorrelation))\n",
    "\n",
    "# Find the number of observations by taking the length of the returns DataFrame\n",
    "nobs = len(returns)\n",
    "\n",
    "# Compute the approximate confidence interval\n",
    "conf = 1.96/sqrt(nobs)\n",
    "print(\"The approximate confidence interval is +/- %4.2f\" %(conf))\n",
    "\n",
    "# Plot the autocorrelation function with 95% confidence intervals and 20 lags using plot_acf\n",
    "plot_acf(returns, alpha=0.05, lags=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can't Forecast White Noise\n",
    "A white noise time series is simply a sequence of uncorrelated random variables that are identically distributed. Stock returns are often modeled as white noise. Unfortunately, for white noise, we cannot forecast future observations based on the past - autocorrelations at all lags are zero.\n",
    "\n",
    "You will generate a white noise series and plot the autocorrelation function to show that it is zero for all lags. You can use np.random.normal() to generate random returns. For a Gaussian white noise process, the mean and standard deviation describe the entire process.\n",
    "\n",
    "Plot this white noise series to see what it looks like, and then plot the autocorrelation function.\n",
    "\n",
    "1. Generate 1000 random normal returns using np.random.normal() with mean 2% (0.02) and standard deviation 5% (0.05), where the argument for the mean is loc and the argument for the standard deviation is scale.\n",
    "2. Verify the mean and standard deviation of returns using np.mean() and np.std().\n",
    "3. Plot the time series.\n",
    "4. Plot the autocorrelation function using plot_acf with lags=20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the plot_acf module from statsmodels\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Simulate white noise returns\n",
    "returns = np.random.normal(loc=0.02, scale=0.05, size=1000)\n",
    "\n",
    "# Print out the mean and standard deviation of returns\n",
    "mean = np.mean(returns)\n",
    "std = np.std(returns)\n",
    "print(\"The mean is %5.3f and the standard deviation is %5.3f\" %(mean,std))\n",
    "\n",
    "# Plot returns series\n",
    "plt.plot(returns)\n",
    "plt.show()\n",
    "\n",
    "# Plot autocorrelation function of white noise returns\n",
    "plot_acf(returns, lags=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Walk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a Random Walk\n",
    "Whereas stock returns are often modeled as white noise, stock prices closely follow a random walk. In other words, today's price is yesterday's price plus some random noise.\n",
    "\n",
    "You will simulate the price of a stock over time that has a starting price of 100 and every day goes up or down by a random amount. Then, plot the simulated stock price. If you hit the \"Run Code\" code button multiple times, you'll see several realizations.\n",
    "\n",
    "1. Generate 500 random normal \"steps\" with mean=0 and standard deviation=1 using np.random.normal(), where the argument for the mean is loc and the argument for the standard deviation is scale.\n",
    "2. Simulate stock prices P:\n",
    "3. Cumulate the random steps using the numpy .cumsum() method\n",
    "4. Add 100 to P to get a starting stock price of 100.\n",
    "5. Plot the simulated random walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 500 random steps with mean=0 and standard deviation=1\n",
    "steps = np.random.normal(loc=0, scale=1, size=500)\n",
    "\n",
    "# Set first element to 0 so that the first price will be the starting stock price\n",
    "steps[0]=0\n",
    "\n",
    "# Simulate stock prices, P with a starting price of 100\n",
    "P = 100 + np.cumsum(steps)\n",
    "\n",
    "# Plot the simulated stock prices\n",
    "plt.plot(P)\n",
    "plt.title(\"Simulated Random Walk\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Drift\n",
    "In the last exercise, you simulated stock prices that follow a random walk. You will extend this in two ways in this exercise.\n",
    "\n",
    "You will look at a random walk with a drift. Many time series, like stock prices, are random walks but tend to drift up over time.\n",
    "In the last exercise, the noise in the random walk was additive: random, normal changes in price were added to the last price. However, when adding noise, you could theoretically get negative prices. Now you will make the noise multiplicative: you will add one to the random, normal changes to get a total return, and multiply that by the last price.\n",
    "\n",
    "1. Generate 500 random normal multiplicative \"steps\" with mean 0.1% and standard deviation 1% using np.random.normal(), which are now returns, and add one for total return.\n",
    "2. Simulate stock prices P:\n",
    "3. Cumulate the product of the steps using the numpy .cumprod() method.\n",
    "4. Multiply the cumulative product of total returns by 100 to get a starting value of 100.\n",
    "5. Plot the simulated random walk with drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 500 random steps\n",
    "steps = np.random.normal(loc=0.001, scale=0.01, size=500) + 1\n",
    "\n",
    "# Set first element to 1\n",
    "steps[0]=1\n",
    "\n",
    "# Simulate the stock price, P, by taking the cumulative product\n",
    "P = 100 * np.cumprod(steps)\n",
    "\n",
    "# Plot the simulated stock prices\n",
    "plt.plot(P)\n",
    "plt.title(\"Simulated Random Walk with Drift\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are Stock Prices a Random Walk?\n",
    "Most stock prices follow a random walk (perhaps with a drift). You will look at a time series of Amazon stock prices, pre-loaded in the DataFrame AMZN, and run the 'Augmented Dickey-Fuller Test' from the statsmodels library to show that it does indeed follow a random walk.\n",
    "\n",
    "With the ADF test, the \"null hypothesis\" (the hypothesis that we either reject or fail to reject) is that the series follows a random walk. Therefore, a low p-value (say less than 5%) means we can reject the null hypothesis that the series is a random walk.\n",
    "\n",
    "1. Import the adfuller module from statsmodels.\n",
    "2. Run the Augmented Dickey-Fuller test on the series of closing stock prices, which is the column 'Adj Close' in the AMZN DataFrame.\n",
    "3. Print out the entire output, which includes the test statistic, the p-values, and the critical values for tests with 1%, 10%, and 5% levels.\n",
    "4. Print out just the p-value of the test (results[0] is the test statistic, and results[1] is the p-value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the adfuller module from statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Run the ADF test on the price series and print out the results\n",
    "results = adfuller(AMZN['Adj Close'])\n",
    "print(results)\n",
    "\n",
    "# Just print out the p-value\n",
    "print('The p-value of the test on prices is: ' + str(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How About Stock Returns?\n",
    "In the last exercise, you showed that Amazon stock prices, contained in the DataFrame AMZN follow a random walk. In this exercise. you will do the same thing for Amazon returns (percent change in prices) and show that the returns do not follow a random walk.\n",
    "\n",
    "1. Import the adfuller module from statsmodels.\n",
    "2. Create a new DataFrame of AMZN returns by taking the percent change of prices using the method .pct_change().\n",
    "3. Eliminate the NaN in the first row of returns using the .dropna() method on the DataFrame.\n",
    "4. Run the Augmented Dickey-Fuller test on the 'Adj Close' column of AMZN_ret, and print out the p-value in results[1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the adfuller module from statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Create a DataFrame of AMZN returns\n",
    "AMZN_ret = AMZN.pct_change()\n",
    "\n",
    "# Eliminate the NaN in the first row of returns\n",
    "AMZN_ret = AMZN_ret.dropna()\n",
    "\n",
    "# Run the ADF test on the return series and print out the p-value\n",
    "results = adfuller(AMZN_ret['Adj Close'])\n",
    "print('The p-value of the test on returns is: ' + str(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Adjustment During Tax Season\n",
    "Many time series exhibit strong seasonal behavior. The procedure for removing the seasonal component of a time series is called seasonal adjustment. For example, most economic data published by the government is seasonally adjusted.\n",
    "\n",
    "You saw earlier that by taking first differences of a random walk, you get a stationary white noise process. For seasonal adjustments, instead of taking first differences, you will take differences with a lag corresponding to the periodicity.\n",
    "\n",
    "Look again at the ACF of H&R Block's quarterly earnings, pre-loaded in the DataFrame HRB, and there is a clear seasonal component. The autocorrelation is high for lags 4,8,12,16,… because of the spike in earnings every four quarters during tax season. Apply a seasonal adjustment by taking the fourth difference (four represents the periodicity of the series). Then compute the autocorrelation of the transformed series.\n",
    "\n",
    "1. Create a new DataFrame of seasonally adjusted earnings by taking the lag-4 difference of quarterly earnings using the .diff() method.\n",
    "2. Examine the first 10 rows of the seasonally adjusted DataFrame and notice that the first four rows are NaN.\n",
    "3. Drop the NaN rows using the .dropna() method.\n",
    "4. Plot the autocorrelation function of the seasonally adjusted DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the plot_acf module from statsmodels\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Seasonally adjust quarterly earnings\n",
    "HRBsa = HRB.diff(4)\n",
    "\n",
    "# Print the first 10 rows of the seasonally adjusted series\n",
    "print(HRBsa.head(10))\n",
    "\n",
    "# Drop the NaN data in the first four rows\n",
    "HRBsa = HRBsa.dropna()\n",
    "\n",
    "# Plot the autocorrelation function of the seasonally adjusted series\n",
    "plot_acf(HRBsa)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
